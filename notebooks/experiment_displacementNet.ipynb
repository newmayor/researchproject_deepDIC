{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "\n",
    "from torchvision.models.resnet import BasicBlock, ResNet\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "def default_loader(path):\n",
    "    return Image.open(path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import BasicBlock, ResNet\n",
    "from torch.nn import init\n",
    "\n",
    "# custom convolutional layer that accounts for transposed image planes as well as conventional 2D conv layers\n",
    "def conv(in_planes, out_planes, kernel_size=3, stride=1, dilation=1, bias=False, transposed=False):\n",
    "    if transposed:\n",
    "        layer = nn.ConvTranspose2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=1, output_padding=1,\n",
    "                                   dilation=dilation, bias=bias)\n",
    "    else:\n",
    "        padding = (kernel_size + 2 * (dilation - 1)) // 2\n",
    "        layer = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, bias=bias)\n",
    "    if bias:\n",
    "        init.constant(layer.bias, 0)\n",
    "    return layer\n",
    "\n",
    "# Returns 2D batch normalisation layer\n",
    "# the range of activation values for each layer is \"forced\" to a normalized distribution of a static mean and cov value, mu & beta\n",
    "# When the activations of a previous layer are forced to a normalized distribution, it makes training of subsequent layers much more efficient\n",
    "def bn(planes):\n",
    "    layer = nn.BatchNorm2d(planes)\n",
    "    # Use mean 0, standard deviation 1 init\n",
    "    init.constant(layer.weight, 1)\n",
    "    init.constant(layer.bias, 0)\n",
    "    return layer\n",
    "\n",
    "\n",
    "# feature extraction using pretrained residual network - this performs as the decoder component of the architecture\n",
    "# Resnet addresses the vanishing gradient problem for very deep networks, using skip connections between layers\n",
    "class FeatureResNet(ResNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(BasicBlock, [3, 14, 16, 3], 1000)\n",
    "        self.conv_f = conv(2,64, kernel_size=3,stride = 1)\n",
    "        self.ReLu_1 = nn.ReLU(inplace=True)\n",
    "        self.conv_pre = conv(512, 1024, stride=2, transposed=False)\n",
    "        self.bn_pre = bn(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_f(x) #upsample 8 to 64. changed from Ru's original model bc my image set has 8 feature channels for some reason?\n",
    "        x = self.bn1(x1)\n",
    "        x = self.relu(x)\n",
    "        x2 = self.maxpool(x) #maxpool with kernel size of 3 and add padding of 1\n",
    "        x = self.layer1(x2) #identity sample 64 to 64\n",
    "        x3 = self.layer2(x) #upsample 64 to 128\n",
    "        x4 = self.layer3(x3) #upsample 128 to 256\n",
    "        x5 = self.layer4(x4) #upsample 256 to 512\n",
    "        x6 = self.ReLu_1(self.bn_pre(self.conv_pre(x5))) #upsample 512 to 1024\n",
    "        return x1, x2, x3, x4, x5,x6\n",
    "\n",
    "\n",
    "class SegResNet(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained_net):\n",
    "        super().__init__()\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = conv(1024, 512, stride=1, transposed=False)\n",
    "        self.bn3_2 = bn(512)\n",
    "        self.conv4 = conv(512,512, stride=2, transposed=True)\n",
    "        self.bn4 = bn(512)\n",
    "        self.conv5 = conv(512, 256, stride=2, transposed=True)\n",
    "        self.bn5 = bn(256)\n",
    "        self.conv6 = conv(256, 128, stride=2, transposed=True)\n",
    "        self.bn6 = bn(128)\n",
    "        self.conv7 = conv(128, 64, stride=2, transposed=True)\n",
    "        self.bn7 = bn(64)\n",
    "        self.conv8 = conv(64, 64, stride=2, transposed=True)\n",
    "        self.bn8 = bn(64)\n",
    "        self.conv9 = conv(64, 32, stride=2, transposed=True)\n",
    "        self.bn9 = bn(32)\n",
    "        self.convadd = conv(32, 16, stride=1, transposed=False)\n",
    "        self.bnadd = bn(16)\n",
    "        self.conv10 = conv(16, num_classes,stride=2, kernel_size=5)\n",
    "        init.constant(self.conv10.weight, 0)  # Zero init\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "        At init, the FeatureResNet() method (aka \"decoder\") is used to extract features \\\n",
    "        from the input space and then those layer activation values are passed into the \\\n",
    "        encoder's conv layers to reduce dimensionality. Then this is done recursively \\\n",
    "        via gradient descent.\n",
    "        '''\n",
    "        x1, x2, x3, x4, x5, x6 = self.pretrained_net(x) #at init, this is used as feature extraction. Then, it's subsequently used as a decoder\n",
    "        \n",
    "        x = self.relu(self.bn3_2(self.conv3_2(x6)))\n",
    "        \n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        #print(x.size())\n",
    "        x = self.relu(self.bn6(self.conv6(x+x4 )))\n",
    "        #print(x.size())\n",
    "        x = self.relu(self.bn7(self.conv7(x+x3 )))\n",
    "        #print(x.size())\n",
    "        x = self.relu(self.bn8(self.conv8(x+x2 )))\n",
    "        #print(x.size())\n",
    "        x = self.relu(self.bn9(self.conv9(x+x1 )))\n",
    "        #print(x.size())\n",
    "        x = self.relu(self.bnadd(self.convadd(x)))\n",
    "        x = self.conv10(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_result = 'trained_model/'\n",
    "model_result = root_result+'model/'\n",
    "log_result = root_result+'log/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet = FeatureResNet()\n",
    "fcn = SegResNet(2,fnet)\n",
    "fcn = fcn.cuda()\n",
    "\n",
    "model_path = 'trained_model/model/param_all_2_149_374'\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))   \n",
    "\n",
    "# fcn.load_state_dict(torch.load(model_result + 'pretrained_displacementnet'))\n",
    "fcn.load_state_dict(torch.load(model_path))\n",
    "\n",
    "fcn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "#define region of interest\n",
    "x1, x2, y1, y2 = 128, 128,1,1     #ylo,yhi,xlo,xhi\n",
    "x100, x200, y100, y200 = 128, 128,1,1     #ylo,yhi,xlo,xhi\n",
    "dx1,dx2,dy1,dy2 = 0,0,0,0\n",
    "\n",
    "h0 = x2-x1\n",
    "w0 = y2-y1\n",
    "\n",
    "disp_1_x = np.zeros((128,128))\n",
    "disp_1_y = np.zeros((128,128))\n",
    "\n",
    "i=0\n",
    "path_img = ''\n",
    "results_path = '/predict_results'\n",
    "img_num = 2 #number of test samples available\n",
    "\n",
    "# for i in range(1,img_num):\n",
    "h0 = x2-x1\n",
    "w0 = y2-y1\n",
    "hnew = int((h0//32+1)*32)\n",
    "wnew = int((w0//32+1)*32)\n",
    "newsize = (wnew,hnew)\n",
    "\n",
    "dir_name = '' #generate more images to use as test samples. Should not use images already used in training\n",
    "img_pair = 'train_image_' #pick randomly from test images dir\n",
    "img_input = os.path.join(dir_name, img_pair)\n",
    "\n",
    "img1 = default_loader(f'{img_input}1.png') #undeformed img\n",
    "# img1_c = img1.crop((y1,x1,y2,x2))\n",
    "# img1_r = img1_c.resize(newsize)\n",
    "img2 = default_loader(f'{img_input}82.png') #deformed img\n",
    "# img2_c = img2.crop((y1,x1,y2,x2))\n",
    "# img2_r = img2_c.resize(newsize)\n",
    "\n",
    "# img_1 = ToTensor()(img1_r)\n",
    "# img_2 = ToTensor()(img2_r)\n",
    "img_1 = ToTensor()(img1)\n",
    "img_1 = img_1[::4,:,:]\n",
    "img_2 = ToTensor()(img2)\n",
    "img_2 = img_2[::4,:,:]\n",
    "print(f\"img_1{img_1.shape} img_2{img_2.shape} \")\n",
    "\n",
    "imgs = torch.cat((img_1/np.max(img_1.numpy()), img_2/np.max(img_2.numpy())), 0)\n",
    "imgs = imgs.unsqueeze(0)\n",
    "imgs = imgs.type(torch.cuda.FloatTensor)\n",
    "imgs = Variable(imgs).cuda()\n",
    "print(f\"{imgs.shape} \")\n",
    "\n",
    "predict = fcn(imgs)\n",
    "predict_np = predict.detach().cpu().numpy().squeeze(0)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(predict_np)\n",
    "# plt.show()\n",
    "\n",
    "print(f\"predict shape: {predict_np.shape}\\n predict shape: {predict.size()}  \")\n",
    "\n",
    "#update region of interest\n",
    "dy1 = dy1+np.mean(predict_np[0,:,:])*(w0)/(wnew)/2.0\n",
    "dy2 = dy2+np.mean(predict_np[0,:,:])*(w0)/(wnew)/2.0\n",
    "dx1 = dx1+np.mean(predict_np[1,:,:])*(h0)/(hnew)/2.0 \n",
    "dx2 = dx2+np.mean(predict_np[1,:,:])*(h0)/(hnew)/2.0\n",
    "\n",
    "print(f\"dy1 {dy1}\\n dy2 {dy2}\\n dx1 {dx1}\\n dx2 {dx2}  \")\n",
    "\n",
    "x10,x20,y10,y20 = x1,x2,y1,y2\n",
    "h0 = x20-x10\n",
    "w0 = y20-y10\n",
    "\n",
    "x1 = np.int(x100-dx1)\n",
    "y1 = np.int(y100-dy1)\n",
    "x2 = round(x200-dx2)\n",
    "y2 = round(y200-dy2)  ###new roi updated\n",
    "    \n",
    "disp_1_x = predict_np/2\n",
    "\n",
    "position = [x1,x2,y1,y2,h0,w0]\n",
    "\n",
    "matname = results_path+'/result_'+str(i)+'_position1.mat'\n",
    "mdic = {\"position\": position, \"label\": \"position\"}\n",
    "savemat(matname,mdic)\n",
    "\n",
    "matname = results_path+'/result_'+str(i)+'_disp_0_x.mat'\n",
    "mdic = {\"disp_1_x\": disp_1_x, \"label\": \"disp_1_x\"}\n",
    "savemat(matname,mdic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load groundtruth disp field data\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import scipy.io as sio\n",
    "\n",
    "dir_groundtruths = '/experiment_samples/gts_severe' #generate more images to use as test samples. Should not use images already used in training\n",
    "filename = os.path.join(dir_groundtruths, img_pair)\n",
    "\n",
    "gt = sio.loadmat(f'{filename}severe.mat')['Disp_field_1'].astype(float)\n",
    "gt = np.asarray(gt)\n",
    "# gt = np.moveaxis(gt, -1, 0)\n",
    "        \n",
    "print(disp_1_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"predict shape: {predict_np[0].shape}\")\n",
    "# [25:225,25:225]\n",
    "plt.figure()\n",
    "plt.imshow(disp_1_x[0])\n",
    "plt.colorbar(label='pixels')\n",
    "plt.title('prediction: \\ndisplacement field u')\n",
    "# plt.figure()\n",
    "# plt.imshow(gt[0])\n",
    "# plt.colorbar(label='pixels')\n",
    "# plt.title('gt: displacement field u')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(disp_1_x[1])\n",
    "plt.colorbar(label='pixels')\n",
    "plt.title('prediction: \\ndisplacement field v')\n",
    "# plt.figure()\n",
    "# plt.imshow(gt[1])\n",
    "# plt.colorbar(label='pixels')\n",
    "# plt.title('gt: displacement field v')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('no warp image')\n",
    "plt.imshow(img1)\n",
    "plt.figure()\n",
    "plt.title('warped image')\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
